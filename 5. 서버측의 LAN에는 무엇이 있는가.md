# 5. 서버측의 LAN에는 무엇이 있는가?

## 웹 서버의 설치 장소

### 사내에 서버를 설치하는 경우

- 사내의 LAN에 서버를 설치하고, 인터넷에서 직접 액세스하는 경우
- 패킷은 가장 가까운 POP에 있는 라우터, 액세스 회선, 서버측 라우터를 경유하여 서버 머신에 도착함.(클라이언트에서 보낼때와 같음)
- 현재는 주류 방식에서 밀려남 -> IP 주소의 부족때문(사내 LAN에 설치한 기기에는 서버뿐만 아니라 클라이언트에서 글로벌 주소를 할당해야 하기 때문, 보안상의 이유)
- 현재는 중간에 방화벽을 두는 방법이 일반화되어있음
- 방화벽은 특정 서버에서 동작하는 특정 애플리케이션에 액세스하는 패킷만 통과시키고, 그 외의 패킷을 차단하는 역할을 하여 애플리케이션에 보안 구멍이 있어도 위험성이 적어짐

### 데이터센터에 서버를 설치하는 경우

- 프로바이더 등이 운영하는 데이터센터라는 시설에 서버를 가지고 들어가서 설치하거나 프로바이더가 소유하는 서버를 빌려쓰는 형태로 운영하는 경우도 잇음
- 데이터센터는 프로바이더의 중심 부분에 있는 NOC에 직접 접속되었거나 프로바이더들이 상호 접속하는 IX에 직결되어 있음
- 인터넷의 중심 부분에 고속 회선으로 접속되었으므로 여기에 서버를 설치하면 고속으로 액세스할 수 있음
- 데이터센터는 내진 구조의 건물에 설치하거나, 자가 발전 장치를 비치하거나, 24시간 입실과 퇴실이 관리되는 곳이 많으므로 회사 안보다는 안정성이 높음



## 방화벽의 원리와 동작

### 패킷 필터링형이 주류

- 서버의 설치 장소와 관계 없이 지금은 바로 앞에 방화벽이 있는 것이 보통
- 특정 서버나 특정 애플리케이션의 패킷만 통과시키는 원리이지만, 네트워크에는 다양한 종류의 패킷이 많으 흐르고, 이 중에서 통과시킬 패킷과 차단할 패킷을 선별하는 것은 간단한 일이 아니기 대문에 다양한 방법이 고안됨

### 패킷 필터링의 조건 설정 개념

- 패킷 필터링의 조건을 설정할 때는 먼저 패킷의 흐름에 착안함
- 수신처 IP 주소와 송신처 IP 주소에 따라 시점과 종점을 판단함
- 인터넷에서 서버를 향해 패킷이 흐르면, 흐름의 종점은 서버가 되므로 이것을 조건으로 설정하고 조건에 해당하는 패킷만 통과시킴
- 즉, 송신처 IP주소는 어디라도 상관없으므로 종점(수신처 IP)이 웹 서버의 IP 주소에 일치하는 패킷은 통과시킨다는 조건을 설정하면 됨
- 패킷을 받으면 확인 응답의 구조가 작동하므로 위의 설정으로만은 방화벽을 설정할 수 없음. 따라서 정해주어야 함

### 애플리케이션을 한정할 때 포트 번호를 사용

- 위의 설명만으로는 인터넷과 서버 사이를 흐르는 패킷은 전부 통과해서 위험한 상태가 됨
- 이와 같이 애플리케이션을 한정할 때는 TCP 헤더나 UDP 헤더에 기록되어 있는 포트 번호를 조건으로 추가함
- 따라서, 패킷 필터링의 표에 포트 번호를 추가하고 서버 이외의 애플리케이션에 대한 액세스를 허가할 경우에는 이 애플리케이션의 포트 번호를 설정하여 통과하도록 함

### 컨트롤 비트로 접속 방향을 판단

- TCP프로토콜을 사용하면 양방향으로 패킷이 흐르므로 단순히 서버에서 인터넷으로 흐르는 패킷을 정지시키면 인터넷에서 서버에 액세스하는 동작도 정지됨
- 따라서, 패킷이 흐르는 방향이 아니라 액세스 방향을 판단하여 정지시켜야 하는데, 여기서 도움이 되는 것이 TCP 헤더에 있는 컨트롤 비트
- TCP는 최초에 Three-way handshake를 하는데 최초의 패킷만 TCP 컨트롤 비트의 SYN이라는 비트가 1로 되고, ACK라는 비트가 0이 됨 -> 이 값을 조사해서 최초의 패킷과 두 번째 이후의 패킷을 판별할 수 있음
- 실제로는 통과시키는 것과 차단하는 것을 완전히 선별할 수 없는 경우도 있는데, DNS 서버에 대한 액세스가 대표적인 예
- DNS 서버에 조회하는 동작은 UDP를 사용하는데, UDP는 TCP와 달리 접속 단계의 동작이 없으므로 TCP처럼 컨트롤 비트에 의해 액세스 방향을 판별할 수 없음.
- 따라서 사내에서 인터넷의 DNS 서버에 액세스하는 것을 허가하고, 인터넷에서 사내의 NDS 서버에 액세스하는 것을 허가하고, 인터넷에서 사내의 NDS 서버에 액세스하는 패킷은 차단한다는 조건을 설정할 수 있음

### 사내 LAN에서 공개 서버용 LAN으로 조건을 설정함

- 서버가 공개 서버용 LAN이고 방화벽을 사용하고 있을 때, 인터넷과 공개 서버용 LAN을 왕래하는 패킷의 조건을 설정할 뿐 아니라 사내 LAN과 인터넷 또는 사내 LAN과 공개 서버용 LAN을 왕래하는 패킷의 조건도 설정해야 함.
- 이 때, 깜빡하고 잘못 설정하면 공개 서버용 LAN에 설치한 서버 전부가 위험한 상태에 빠지므로 신중하게 조건을 설정해야 함

### 밖에서 사내 LAN으로 액세스할 수 없음

- 패킷 필터링형 방화벽은 패킷을 통과시킬지, 차단시킬지를 판단할 뿐만 아니라 주소 변환의 기능도 갖고 있으므로 설정이 필요함
- 인터넷과 사내 LAN을 왕래하는 패킷은 주소 변환을 해야 하므로 설정이 필요함 -> 구체적으로 패킷 필터링과 마찬가지로 패킷의 시점과 종점을 조건으로 지정한 후 주소 변환이 필요한 경우에는 주소 변환을 하고, 변환이 필요하지 않은 경우에는 변환하지 않도록 설정
- 주소 변환을 이용하면 당연히 인터넷 측에서 사내 LAN에는 액세스할 수 없게 됨. 따라서 사내 LAN에 대한 액세스를 금지하도록 패킷 필터링의 조건을 설정할 필요가 없음

### 방화벽을 통과함

- 방화벽에서 패킷을 판정한 후, 통과시킬지와 차단할지를 결정하여 차단의 경우 패킷을 버리고 버린 기록을 남김
- 통과시킨다는 판정을 내린 경우에는 패킷을 중계하는데, 이 중계 동작은 라우터의 동작과 같음
- '패킷 필터링'이라는 구조는 방화벽용의 특별한 구조가 아닌 라우터의 패킷 중계 기능 중에서 부가 기능이라고 생각하면 됨. 그러나,  판정 조건이 복잡해지면 라우터의 명령으로 설정하기가 어려워지고, 패킷을 버린 기록을 남기는것도 라우터에 크게 부담스로운 작업이기 때문에 전용 하드웨어나 소프트웨어를 사용함

### 방화벽으로 막을 수 없는 공격

- 패킷의 내용을 조사하지 않으면 위험한지 판단할 수 없어서 방화벽의 구조는 이러한 상황에 대처할 수 없음
- 해결책
  - 원인이 서버 스포트웨어의 버그에 있으므로 버그를 고쳐서 다운되지 않도록 하는 것. -> 이런 종류의 버그 중에서 위험성이 높은 것은 정보가 보안 구멍으로 널리 공개되어 버그를 수정하지 않은 새 버전이 배포되는 경우
  - 패킷의 내용을 조사하여 위험한 데이터가 포함되어 있는 경우에 패킷을 차단하도록 장치나 소프트웨어를 방화벽과는 별도로 준비하는 방법



## 복수 서버에 리퀘스트를 분배한 서버의 부하 분산

### 처리 능력이 부족하면 복수 서버로 부하 분산됨

- 서버에 액세스가 증가할 때는 서버로 통하는 회선을 빠르게 하는 방법이 효과적이지만, 회선을 빠르게 하는 것만으로도 부족할 수 있음
- 이에 따라 서버 한 대당 처리량을 줄이기 위해 분산 처리를 함
- 가장 간단한 방법은 단순히 여러 대의 서버를 설치하고 한 대가 담당하는 사용자 수를 줄이는 방법
- 방법은 여러가지가 있으나, DNS 서버에서 분배하는 방법이 가장 간단함
- 서버에 액세스할 때 DNS 서버에 조회하여 IP 주소를 조사하는데, DNS 서버에 같은 이름으로 여러 대의 서버를 등록해 놓으면 DNS 서버는 조회가 있을 때마다 차례대로 IP 주소를 되돌려줌 -> 라운드 로빈 방식
- 라운드 로빈 방식은 서버가 동작하지 않는지 확인하지 ㅁ소하므로 서버가 정지해도 상관하지 않고 IP주소를 회답해 버림

### 부하 분산 장치를 이용해 복수의 서버로 분할됨

- 이러한 좋지 않은 상태를 피하기 위해 부하 분산 장치 또는 로드 밸런서 등으로 부르는 기기가 고안되었음
- 부하 분산 장치를 사용할 때는 먼저 부하 분산 장치를 웹 서버 대신 DNS 서버에 등록함
- 그러면 패킷이 부하 분산 장치로 향하게 되고 어떤 서버에 리퀘스트를 전송해야 할지 판단함
- 판단 근거는 여러 가지가 있지만, 대화가 복수의 페이지(웹의 경우)에 걸쳐있는지에 따라 판단기준이 다름
- 복수 페이지에 걸쳐있지 않은 단순한 액세스라면 서버의 부하 상태가 판단 근거가 될 것임
- 서버와 정기적으로 정보를 교환하여 CPU나 메모리의 사용률 등을 수집하고, 이것을 바탕으로 어느 서버의 부하가 낮은지 판단하거나, 시험 패킷을 서버에 보내 응답 시간으로 부하를 판단하는 방법이 일반적
- 정보 교환은 너무 자주도, 너무 뜸하게도 하면 안좋기 때문에 적절히 조절해야 함
- 복수 페이지에 걸쳐있을 때는 서버의 부하에 관계 없이 이전의 리퀘스트와 같은 서버에 전송해야 함. 이렇게 하려면 먼저 복수 페이지에 걸쳐있는지 판단해야 함
- HTTP가 서버에 액세스할 때는 TCP의 접속 동작부터 다시 수행함 -> 전후의 관계를 판단하는 중관 가정이 의도적으로 생략됨
- 전후 관계를 알지 않아도 리퀘스트의 송신처 IP 주소가 같다면 일련의 것이라는 식으로 판단할 수 있지만, 프록시를 사용하면 리퀘스트의 송신처 IP 주소가 프록시의 IP 주소로 되어 리퀘스트를 보낸 클라이언트가 누구인지 모르게 됨
- 따라서 전후 관계를 판단하기 위해 양식에 입력한 데이터를 보낼 때 그 안에 전후의 관련을 나타내는 정보를 부가하거나 HTTP의 사용을 확장하여 전후 관계를 판단하기 위한 정보를 HTTP 헤더 필드에 부과하는 방법 사용




## 캐시 서버를 이용한 서버의 부하 분산(웹)

### 캐시 서버의 이용

- 데이터베이스 서버와 웹 서버와 같은 역할에 따라 서버를 나누는 방법이 있음. 이러한 역할별 분산 처리 방법 중의 하나가 캐시 서버를 사용하는 방법
- 캐시 서버 - 프록시라는 구조를 사용하여 데이터를 캐시에 저장하는 서버
- 프록시 - 서버와 클라이언트 사이에 들어가서 서버에 대한 액세스 동작을 중개하는 역할을 하는데, 액세스 동작을 중개할 때 서버에서 받은 데이터를 디스크에 저장해 두고 서버를 대신하여 데이터를 클라이언트에 반송하는 기능을 갖고 있음(캐시 기능)
- 캐시에 데이터를 저장한 후 웹 서버측에서 데이터가 변경되면 캐시의 데이터를 사용할 수 없음
- 또한 CGI 애플리케이션 등이 출력하는 페이지 데이터도 내용이 매번 달라지므로 캐시를 이용할 수 없음

### 캐시 서버는 갱신일로 콘텐츠를 관리함

- 캐시 서버를 사용할 때는 부하 분산 장치와 마찬가지로 캐시 서버를 서버 대신 DNS 서버에 등록함
- 그러면 사용자는 캐시 서버에 메시지를 보냄. 이 때의 수신 동작은 서버의 수신 동작과 같음
- 메시지를 받으면 캐시 서버는 리퀘스트 메시지의 내용을 조사하고, 데이터가 자신의 캐시에 저장되었는지 조사함
- 자신에게 저장되어 있지 않은 경우
  캐시 서버는 리퀘스트 메시지에 캐시 서버를 경유한 것을 나타내는 'via'헤더 필드를 추가하여 서버에 리퀘스트를 전송함.
  - 한 대의 캐시로 여러 대의 서버의 데이터를 캐시에 저장하는 경우에는 리퀘스트 메시지의 내용에 따라 전송 대상의 서버를 판단하는 것 같은 방법이 필요함
  - 대표적으로 리퀘스트 메시지의 URI에 쓰여있는 디렉토리를 보고 판단하는 방법이 있음
  - 캐시 서버에 /dir1/이나 /dir2/와 같은 URI를 전송하여 각각의 경우 다른 DNS로 연결시킴
- 이렇게 클라이언트와 서버 사이를 중개하는 것이 프록시 구조
- 자신에게 저장 되어있는 경우
  - 리퀘스트 메시지를 받아 캐시에 저장되었는지 조사
  - 서버측에서 데이터가 변경되었는지 조사하기 위한 'If-Modified-Since'라는 헤더 필드를 추가하여 서버에 전송함
  - 변경이 없으면 변경이 없다는 응답 메시지를 반송
  - 캐시에 저장한 데이터를 추출하여 사용자에게 보냄

### 프록시의 원점은 포워드 프록시

- 포워드 프록시 - 프록시의 원형으로, 프록시라는 구조가 원래 클라이언트 측에 있었다는 것
- 포워드 프록시는 캐시를 이용하며 방화벽을 실현한다는 중요한 목적이 있었음
- 인터넷에서의 부정침입을 막기 위해 필요한 패킷만 통과시키는 방법인 프록시라는 구조를 고안
- 프록시는 리퀘스트의 내용을 조사한 후 전송하므로 리퀘스트의 내용에 따라 액세스가 가능한지 판단할 수 있었음
- 포워드 프록시를 사용할 경우에는 보통 브라우저의 설정 화면에 준비되어 있는 프록시 서버라는 항목에 포워드 프록시의 IP주소를 설정
- 포워드 프록시를 사용할 경우에는 URI의 대부분에 http://....라는 URL이 그대로 쓰여있으므로 URL이 전송 대상이 됨. 
- 서버측에 두는 캐시 서버는 설정해 둔 웹 서버에만 전송할 수 있으므로 상당히 다름

### 포워드 프록시를 개량한 리버스 프록시

- 포워드 프록시를 사용할 경우에는 브라우저에 대한 설정이 반드시 필요함
- 그러나 브라우저에 설정이 필요하다는 점은 이런 수고나 장애의 원인뿐만 아니라 다른 제약 사항이 되기도 함.
- 따라서 클라이언트 바로 앞에 프록시를 두는 방법을 선택하지 않음
- 이에 따라 리퀘스트 메시지의 URI에 쓰여있는 디렉토리명과 전송 대상의 서버를 대응시켜서 URI부분에 http://...라고 쓰여있지 않은 보통의 리퀘스트 메시지를 전송할 수 있도록 하였음. 이것이 서버측에 설치하는 캐시 서버에 채택하고 있는 방식으로 리버스 프록시라고 함

### 트랜스페어런트 프록시

- 패킷의 맨 앞에 있는 IP 헤더에는 수신처 IP 주소가 기록되어 있으므로 이것을 조사하면 액세스 대상 서버가 어디인지 알 수 있는데, 이를 트랜스페어런트 프록시라고 함
- 이 방법은 보통의 리퀘스트 메시지를 전송할 수 있으므로 포워드 프록시처럼 브라우저에 설정할 필요가 없음
- 또한 전송 대상을 캐시 서버에 설정할 필요도 없고, 어느 서버에서나 전송할 수 있음
- 트랜스페어런트 프록시는 브라우저에 설정하지 않으므로 브라우저는 서버에 리퀘스트 메시지를 보냄.
- 리버스 프록시와 같이 DNS 서버에 등록하는 방법이라면 이 리퀘스트 메시지가 프록시에 도착하지만, 트랜스페어런트 프록시는 DNS 서버에 등록하지 않음. -> 브라우저에서 서버로 흘러갈 뿐 트랜스페어런트 프록시에는 도착하지 않음
- 따라서 브라우저에서 서버로 리퀘스트 메시지가 흘러가는 길에 트랜스페어런트 프록시를 설치함
- 메시지가 트랜스페어런트 프록시를 통과할 때 그것을 가로챔
- 리퀘스트 메시지가 흐르는 길이 많으면 여기에 전부 트랜스페어런트 프록시를 설치해야 하므로 길이 한 개로 수렴하는 형대로 네트워크를 만들고, 수렴되는 곳에 트랜스페어런트 프록시를 설치하는 것이 보통임




## 5. 콘텐츠 배포 서비스

### 콘텐츠 배포 서비스를 이용한 부하 분산

- 서버측에 캐시 서버를 두는 방법은 서버의 부하를 경감하는 효과는 있지만, 트래픽을 억제하는 효과는 없음 -> 트래픽 억제를 위해서는 클라측에 캐시 서버를 두어야 함
- 클라이언트측에 두는 캐시 서버는 클라이언트측의 네트워크를 운영 관리하는 사람이 소유하므로 서버 운영자가 제어할 수 없음
- 캐시 서버는 놓는 장소에 따라 장점과 단점이 있지만 양쪽의 좋은 점을 취한 방법도 있음 -> 프로바이더와 꼐약하여 서버 운영자가 제어할 수 있는 캐시 서버를 클라이언트측의 프로바이더에 두는 방법
- 프로바이더에 두는 방법은 서버 운영자가 제어할 수 있다는 장점이 있지만, 어디에서 액세스하는지 알 수 없음
- 따라서, 이를 실현하려면 프로바이더의 POP전부에 캐시 서버를 설치해야 하지만, 수가 너무 많아 비현실적임
- 해결책 - 중요한 프로바이더에 중점을 둠.
- 콘텐츠 배포 서비스(CDS) - 프로바이더가 캐시 서버를 설치하고, 이것을 서버 운영자에게 대출하는 서비스
- CDSP(프로바이더)는 중요한 프로바이더와 계약하고 그곳에 다수의 캐시 서버를 설치함. 또한 서버 운영자와도 계약하여 서버와 CDSP의 캐시 서버를 연대시킴
- 캐시 서버는 다수의 서버의 데이터를 캐시에 저장할 수 있으므로 CDSP가 설치한 캐시 서버를 다수의 서버 운영자가 공동으로 이용할 수도 있음

### 가장 가까운 캐시 서버의 관점

- 콘텐츠 배포 서비스를 사용하는 경우 인터넷 전체에 설치된 다수의 캐시 서버를 이용함
- 이러한 상황에서는 다수가 있는 캐시 서버 중에서 가장 가까운 캐시 서버를 찾아내고, 클라이언트가 여기에 액세스하도록 중재하는 구조가 필요함
- 구조 1 - 복수 서버를 설치하여 부하를 분산시킬 때 DNS 서버에서 액세스를 분배하는 것과 비슷한 방법. 즉, DNS 서버가 웹 서버의 IP 주소를 회답할 때 가장 가까운 캐시 서버의 IP 주소를 회답하도록 DNS 서버를 세밀하게 설정하는 방법
- 보통의 DNS 서버의 경우, 한 이름에 복수의 IP 주소를 대응시키면 라운드 로빈 방식으로 차례대로 IP 주소를 회답함. -> 먼 위치에 있는 캐시 서버의 IP 주소를 되돌려줄지도 모르기 때문에 라운드 로빈이 아닌 클라이언트와 캐시 서버의 거리를 판단하여 클라이언트에 가장 가까운 캐시 서버의 IP 주소를 회답하도록 함

### 리피터용 서버로 액세스 대상을 분배함

- HTTP의 사양에는 'Location'이라는 헤더 필드가 정의되어있음 - 서버의 데이터를 다른 서버로 옮기는 경우에 사용하는 것으로, '그 데이터는 이쪽 서버에 있으므로 그쪽으로 다시 액세스하라'는 의미
- 이렇게 다른 서버에 액세스하도록 처리하는 것을 **리다이렉트**라고 하며 이것을 사용하여 액세스 대상을 가장 가까운 캐시 서버로 돌리는 것이 또 한가지 방법
- 리다이렉트에 의해 가장 가까운 캐시 서버를 클라이언트에 통지할 때는 리다이렉트용 서버를 웹 서버측의 DNS서버에 등록
- 클라이언트는 여기에 HTTP의 리퀘스트 메시지를 보냄
- 리다이렉트용 서버에는 DNS 서버와 같이 라우터에서 모은 경로 정보가 잇으며, 여기에서 가장 가까운 캐시 서버를 찾음
- 캐시 서버를 나타내는 Location 헤더를 붙여 응답을 돌려보내면 클라이언트는 캐시 서버에 다시 액세스함
- 이 방법은 HTTP 메시지의 대화가 증가하므로 그만큼 오버헤드가 많지만, 정밀도가 높다는 장점이 있음

### 캐시 내용의 갱신 방법에서 성능의 차이가 난다

- 캐시는 갱신된 내용의 유무를 확인한다는 동작이 있기 때문에 응답 시간이 악화될 수 있음
- 이를 개선하려면 서버에서 원래 데이터를 갱신할 경우 이것을 즉시 캐시 서버에 반영해야 함
- 콘텐츠 배포 서비스에 이용하는 캐시 서버에는 이러한 대책이 내장되어있음
- 웹 페이지는 사전에 준비해 두는 정적인 것이 아니라 리퀘스트를 받았을 때 CGI 애플리케이션 등에서 동적으로 페이지를 만드는 경우도 있음 -> 이 경우는 캐시 서버에 데이터를 저장하면 안됨
- 위 경우는 페이지 전체를 캐시에 저장하지 않고 애플리케이션에서 만든 부분, 즉 매번 페이지의 내용이 달라지는 부분과 달라지지 않는 부분을 구분하고 변하지 않는 부분만 캐시에 저장해야 함
- ​